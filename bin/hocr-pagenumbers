#!/usr/bin/env python

import sys
import argparse

import re
from roman import fromRoman, toRoman, InvalidRomanNumeralError
from hocr.parse import hocr_page_iterator, hocr_page_to_word_data

# TODO:
#
# - Clean up code
# - Add other numbering schemes
# - Test with logistic regression
# - Add confidence based on logistic regression and other data (maybe also word
#   confidence?)
# - Test with items in pagenumber-test-data - also the oddball ones (maybe add
#   new schemes for them, like 'arabic +' - to allow (8) as 8, etc)
# - Compare with ILL
#
# - Maybe at the end, extrapolate outside of our regular bounds in case any
#   values are still 'None' (but with much lower confidence)
# - Add further extrapolation option (also logistic regression?)
# - Optimise code some to prevent too many back and forth conversions

# - Mention: "Versatile Page Numbering Analysis", Hervé Déjean, Jean-Luc Meunier
#
# TO HANDLE:
# * The page numbers are of the form 22/314, 23/315, 71..363 and so forth, the
#   OCR picks them up, but I am not sure if the module knows what to do with it.
# * (12)10, (12)11, (12)12
# * (7), (8), (9), etc


# syntatic form
# expected monotonic increase (in steps?) - equality test given N steps
# tolerance for holes & allow extrapolation


class ArabicNumberingScheme(object):
    PAGENO_RE = re.compile(r'([A-Z]{1})?[0-9 ]+[-/]?([0-9 ]+)$')
    SUPPORT_EXTRAPOLATION = True

    def syntactic_match(self, s):
        v = ArabicNumberingScheme.PAGENO_RE.match(s)

        if v:
            try:
                int(s)
            except:
                v = False

        return v

    def is_increase(self, base, steps, check):
        return base.num_value + steps == check.num_value

    def numeral_value(self, s):
        return int(s)

    def extrapolate_sequence(self, start, end):
        start_pageidx, start_pagenumber = start
        end_pageidx, end_pagenumber = end

        new_sequence = []

        for pageidx, val in zip(range(start_pageidx, end_pageidx+1),
                                range(int(start_pagenumber.num_value), int(end_pagenumber.num_value+1))):
            new_sequence.append((pageidx, PageNumberCandidate(val, self)))

        return new_sequence


class RomanNumberingScheme(object):
    SUPPORT_EXTRAPOLATION = True

    def syntactic_match(self, s):
        try:
            v = fromRoman(s.upper())
            return True
        except InvalidRomanNumeralError:
            return False

    def is_increase(self, base, steps, check):
        return base.num_value + steps == check.num_value

    def numeral_value(self, s):
        return fromRoman(s.upper())

    def extrapolate_sequence(self, start, end):
        start_pageidx, start_pagenumber = start
        end_pageidx, end_pagenumber = end

        new_sequence = []

        for pageidx, val in zip(range(start_pageidx, end_pageidx+1),
                                range(int(start_pagenumber.num_value), int(end_pagenumber.num_value+1))):
            new_sequence.append((pageidx, PageNumberCandidate(toRoman(val), self)))

        return new_sequence




NUMBER_SCHEMES = [
    ArabicNumberingScheme(),
    RomanNumberingScheme(),
]


class PageNumberCandidate(object):
    def __init__(self, value, scheme):
        # page idx?
        self.value = value
        self.num_value =  scheme.numeral_value(value)
        self.scheme = scheme


def find_hocr_matches(hocrfile):
    page_matches = []

    page_stop = 10000
    for pageidx, page in enumerate(hocr_page_iterator(hocrfile)):
        word_data = hocr_page_to_word_data(page)
        matches = []

        for par in word_data:
            for line in par['lines']:
                for word in line['words']:
                    for scheme in NUMBER_SCHEMES:
                        if scheme.syntactic_match(word['text']):
                            match = PageNumberCandidate(word['text'], scheme)
                            matches.append(match)

        page_matches.append(matches)

        if pageidx > page_stop:
            break

    return page_matches


def fits_sequence(sequence, pageidx, match):
    last_seq = sequence[-1]

    last_seq_pageidx, last_seq_val = last_seq
    step = pageidx - last_seq_pageidx

    if match.scheme.is_increase(last_seq_val, step, match) and match != last_seq_val and pageidx != last_seq_pageidx:
        return True

    return False


def greedy_sequence_enumeration(page_matches):
    current_sequences = []
    parked_sequences = []

    # TODO: see if we want to tweak this some, especially if we add logistic regression
    #density_threshold = 0.2
    density_threshold = 0.3

    for pageidx, matches in enumerate(page_matches):
        for match in matches:
            fits = False

            for seq in current_sequences:
                if fits_sequence(seq, pageidx, match):
                    seq.append((pageidx, match))
                    fits = True
                    break

            # Create new sequence
            if not fits:
                current_sequences.append([(pageidx, match)])

        # Figure out which sequences to park (so that we don't have to take them
        # into account in the analysis going forward)
        park_idx = []
        for idx, sequence in enumerate(current_sequences):
            seq_len = len(sequence)

            seq_start = sequence[0][0]
            seq_tail = pageidx

            seq_diff = seq_tail - seq_start
            density = seq_len / (seq_tail - seq_start) if seq_diff != 0 else 1

            if density < density_threshold:
                move_seq = current_sequences.pop(idx)
                parked_sequences.append(move_seq)

    # Park remaining sequences
    for sequence in current_sequences:
        parked_sequences.append(sequence)
    current_sequences = []

    # Filter 1-length out
    parked_sequences = list(filter(lambda x: len(x) > 1, parked_sequences))

    return parked_sequences


class State(object):
    def __init__(self, pageidx, value):
        self.pageidx = pageidx
        self.value = value
        self.links = {}

    def link(self, other_state, cost):
        self.links[other_state] = cost

    def get_cost(self, other_state):
        try:
            return self.links[other_state]
        except:
            # TODO: Investigate this, we really want the cost to be defined for
            # everything
            #print('Failed for page idx %d with value %s and page idx %d with value %s' % (self.pageidx, self.value, other_state.pageidx, other_state.value))
            return 2.

    def __repr__(self):
        return '(%s, %s)' % (self.pageidx, self.value)

        #s = '%s -> [' % self.value
        #vals = list(map(lambda x: str(x.value) if x.value else 'None', self.links))
        #s += ','.join(vals)
        #s += ']'
        #return s


# TODO: This is sequence selection
# TODO: Should F=5, or some other value ??
def create_graph(sequences, page_count, F=5):
    # XXX: This requires the gaps in sequences to be filled up

    graph = []

    NONE_COST = 1. # Max cost

    page_states = {}
    for page in range(page_count):
        page_states[page] = [State(page, None)]

    for sequence in sequences:
        N = len(sequence)
        sequence_states = []

        for idx, (pageidx, value) in enumerate(sequence):
            s = State(pageidx, value)
            if (idx > 0):
                cost = 1 - (F / N)
                # XXX: The algorithm we work with currently uses cost, not score, so we add 1 - ... here
                sequence_states[idx-1].link(s, 1 - cost)

                #sequence_states[idx-1].link(s, cost)

            sequence_states.append(s)
            page_states[pageidx].append(s)

    # Now connect all the states of the previous layer to the None state of the
    # next layer and connect all the None states to the other sequences
    for page in range(1, page_count):
        prev_page_states = page_states[page - 1]
        current_none_state = page_states[page][0]

        # XXX: It should also be possible for sequences to jump from the end of
        # one sequence to another, the code does not allow for this yet
        # unfortunately

        for prev_page_state in prev_page_states:
            # TODO: We might want some of these to be negative if a state is
            # leaving its sequence early
            prev_page_state.link(current_none_state, NONE_COST)

        prev_page_none_state = prev_page_states[0]
        for page_state in page_states[page]:
            prev_page_none_state.link(page_state, NONE_COST)



    list_page_states = []
    for page in range(page_count):
        list_page_states.append(page_states[page])

    return list_page_states


def fill_holes(sequences):
    new_sequences = []

    for sequence in sequences:
        scheme = sequence[0][1].scheme
        if scheme.SUPPORT_EXTRAPOLATION:
            start_pageidx = sequence[0][0]
            end_pageidx = sequence[-1][0]
            start_val = sequence[0][1]
            end_val = sequence[-1][1]
            new_sequence = scheme.extrapolate_sequence((start_pageidx, start_val),
                                                       (end_pageidx, end_val))
            new_sequences.append(new_sequence)
        else:
            new_sequences.append(sequence)

    return new_sequences

def create_page_json(pagenos):
    data = {'pages': [], 'confidence': 'todo', 'identifier': 'todo'}

    for (pageidx, pagenoval) in pagenos:
        data['pages'].append({'leafNum': pageidx,
                              'pageNumber': pagenoval.value if pagenoval else ''})

    return data


def pagenos_from_trellis(best_path, trellis):
    pagenos = []

    last_state = None
    for page_idx, (choice_idx, vals) in enumerate(zip(best_path, trellis)):
        #print('\tpicked: %s -> %s' % (last_state, vals[choice_idx]))
        #print()

        if last_state is not None:
            #print('New choices:',)
            for link in last_state.links:
                pass
                #print(last_state, '->', link, ' with cost', last_state.get_cost(link))


        last_state = vals[choice_idx]

        # +1 for 1-based page numbering just so that we can understand it in our
        # debug prints
        pagenos.append((page_idx, last_state.value))

    return pagenos


def process_file(hocrfile, outfile):
    # Step 1: find candidates for each page (with coords)
    #
    # XXX: Make this into a function

    page_matches = find_hocr_matches(hocrfile)

    #from pprint import pprint
    #pprint(page_matches)

    sequences = greedy_sequence_enumeration(page_matches)
    ##pprint(sequences)

    sequences = fill_holes(sequences)
    #pprint(sequences)

    trellis = create_graph(sequences, len(page_matches))
    #pprint(trellis)

    from viterbi_trellis import ViterbiTrellis
    v = ViterbiTrellis(trellis, lambda x: 1., lambda x, y: x.get_cost(y))
    best_path = v.viterbi_best_path()
    #print(best_path)

    pagenos = pagenos_from_trellis(best_path, trellis)

    # TODO: Formal analysis with logistic regression

    page_json = create_page_json(pagenos)
    outfile_fp = open(outfile, 'w')
    import json
    json.dump(page_json, outfile_fp, indent=' ' * 4)
    outfile_fp.close()


    #debug(page_matches)




if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='hOCR to plaintext')
    parser.add_argument('-f', '--infile', help='Filename to read',
                        type=str, default=None)
    parser.add_argument('-o', '--outfile', help='Filename to write to',
                        type=str, default=None)
    args = parser.parse_args()

    process_file(args.infile, args.outfile)
